---
title: "Evaluations"
description: "Test and validate your AI agent's performance with custom evaluation suites"
---

Create custom evaluation suites to batch test your agent's performance and ensure consistent, high-quality responses across different scenarios.

<Frame>
  ![AI Agent evaluation details interface](/images/guides/ai-agents/evaluations-start-page.png)
</Frame>

## How evaluations work

1. **Define evaluation questions** - Build a set of test questions for each agent. You can either:
   - Manually create questions that represent common use cases
   - Select responses from existing agent conversations in the admin page to add to your evaluation set

     <Accordion title="Adding questions from existing conversations">
       <Frame>
         ![AI Agent evaluation details interface](/images/guides/ai-agents/evals-add-to-evals-1.png)
       </Frame>
     </Accordion>
2. **Run batch tests** - Execute all prompts in your evaluation set against the agent to see how it responds

     <Accordion title="Running batch tests">
       <Frame>
         ![Running batch tests](/images/guides/ai-agents/run-batch-tests.png)
       </Frame>
     </Accordion>
3. **Review results** - Manually review the agent's responses to ensure they meet your quality standards and expectations

     <Accordion title="Reviewing evaluation results">
       <Frame>
         ![Reviewing evaluation results](/images/guides/ai-agents/review-evaluation-results.png)
       </Frame>
     </Accordion>

## Using feedback to improve evaluations

Encourage your team to actively use the thumbs-up/thumbs-down feature when interacting with AI agents. This feedback helps admins in two key ways:

- **Identify improvement areas** - Thumbs-down responses highlight where the agent needs work
- **Build better evaluation sets** - Filter and easily add thumbs-down responses to your evaluation suite to test fixes and prevent regressions

<Accordion title="View filtering in the Admin Panel">
<Frame>
  ![Building better evaluation sets](/images/guides/ai-agents/build-better-evaluation-sets.png)
</Frame>
</Accordion>

This systematic testing approach helps you:

- Verify agent performance before deploying changes
- Ensure consistency across common queries