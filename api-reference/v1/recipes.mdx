---
title: "API Recipes"
description: "A collection of practical, copy-paste examples showing how to combine Lightdash API endpoints to achieve common workflows."
---

## What are API Recipes?

The Lightdash API is intentionally modular: most endpoints return small, focused pieces of information. While this keeps the API flexible, some real-world tasks require calling multiple endpoints together or assembling responses in a certain order.

**API Recipes** are short guides that show you _how to do exactly that_. Each recipe walks through:

- **What you’re trying to accomplish** (e.g., fetch SQL for all charts in a project)
- **Which endpoints to call and in what order**
- **Example requests** in `curl`
- **Example JSON responses**
- **Optional scripts** in JS/Python when useful

## When should you use Recipes?

Use a recipe when:

- You want to automate a workflow that spans multiple endpoints
- You need to query Lightdash programmatically but aren’t sure which calls to chain
- You want real examples of authentication, pagination, or interpreting metric queries
- You’re building internal tooling or dashboards powered by the Lightdash API

For example, Lightdash doesn’t provide a single endpoint that returns “SQL for every chart,” but you _can_ accomplish this by combining the chart-listing endpoint with the metric-query endpoint—so we provide a ready-made recipe.

## Before You Run a Recipes

You will need:

- Python 3.9+ installed
- A Personal Access Token (PAT)
- Your Lightdash instance URL
- The project UUID you want to modify

## Extract SQL from a Saved Lightdash Chart Using the API

This recipe shows how to fetch the underlying SQL for any saved chart by:

1. Retrieving the chart
2. Extracting its `metricQuery`
3. Compiling that query into SQL

### Step 1: Fetch the saved chart

(You must first create a Personal Access Token (PAT))

```
curl -H "Authorization: ApiKey ldpat_{{your_PAT_token}}" \
  https://analytics.lightdash.cloud/api/v1/saved/{{your_chart_uuid}}
```

### Step 2: Extract the `metricQuery` JSON

```
curl -s \
  -H "Authorization: ApiKey ldpat_{{your_PAT_token}}" \
  https://analytics.lightdash.cloud/api/v1/saved/{{your_chart_uuid}} \
  | jq '.results.metricQuery' > metricQuery.json
```

This writes the chart’s semantic query definition to `metricQuery.json`.

### Step 3: Compile the `metricQuery` into SQL

```
curl -s -X POST \
  -H "Authorization: ApiKey ldpat_{{your_PAT_token}}" \
  -H "Content-Type: application/json" \
  -d @metricQuery.json \
  https://analytics.lightdash.cloud/api/v1/projects/{{your_project_uuid}}/explores/{{your_explore_name}}/compileQuery \
  | jq '.results.query'
```

### Example Output

```
{
  "status": "ok",
  "results": {
    "query": "SELECT
  `accounts`.segment AS `accounts_segment`,
  AVG(`deals`.amount) AS `deals_average_amount`,
  SUM(`deals`.amount) AS `deals_total_amount`
FROM `your_project`.`your_dataset`.`accounts` AS `accounts`
LEFT OUTER JOIN `your_project`.`your_dataset`.`deals` AS `deals`
  ON (`accounts`.account_id) = (`deals`.account_id)
GROUP BY 1
ORDER BY `deals_average_amount` DESC
LIMIT 500"
  }
}
```

### One-Step Solution (pipeline version)

```
curl -s -H "Authorization: ApiKey ldpat_{{your_PAT_token}}" \
  https://analytics.lightdash.cloud/api/v1/saved/{{your_chart_uuid}} \
  | jq '.results.metricQuery' \
  | curl -s -X POST \
      -H "Authorization: ApiKey ldpat_{{your_PAT_token}}" \
      -H "Content-Type: application/json" \
      -d @- \
      https://analytics.lightdash.cloud/api/v1/projects/{{your_project_uuid}}/explores/{{your_explore_name}}/compileQuery \
  | jq '.results.query'
```

## Rename Models Inside Saved Charts

This script updates model names inside all saved charts in a Lightdash project.\
It renames occurrences of a model across:

- dimensions
- metrics
- filters
- sorts
- tableConfig
- chartConfig
- table calculations

⚠️ **Does not update:**\
conditional formatting, reference lines, dashboards, dashboard filters, or charts inside dashboards.

### Before You Run This Script

You will need:

1. **Node.js** installed
4. The old and new model names
5. A copy of [rename_models_in_charts.js](https://github.com/lightdash/lightdash-api-examples/blob/main/javascript/rename_models_in_charts.js)

### Step 1: Install dependencies

```
yarn
# or
npm i
```

### Step 2: Update rename_models_in_charts.js script variables

In the script, replace:

```
const projectUuid = `3675b69e-8324-4110-bdca-059031aa8da3`
const apiKey = '<my-api-key>'
const oldModel = 'customers'
const newModel = 'users'
const testing = true   // set to false to actually update
const debug = false    // set to true to see detailed logs
```

### Step 3: Run the script

If you want a dry run (no changes), keep:

```
const testing = true
```

When you are ready to apply updates:

```
const testing = false
```

Then run [rename_models_in_charts.js](https://github.com/lightdash/lightdash-api-examples/blob/main/javascript/rename_models_in_charts.js):

```
node rename_models_in_charts.js
```

## Dashboard Cleanup & Usage Audit for a Project (Python Utility Script)

This Python script helps you **clean up dashboards** in a specific Lightdash project. It uses the v2 Content API and can export results to CSV, Excel, or JSON for deeper analysis. This script provides:

- A complete list of all dashboards with metadata for that project
- View counts and first viewed dates
- Creation and last modification dates
- Dashboard organization by spaces
- Cleanup recommendations based on usage patterns (never viewed, low engagement, stale, no description, etc.)

### Before You Run This Script

You will need:

- A copy of [find_dashboards.py](https://github.com/lightdash/lightdash-api-examples/blob/main/python/find_dashboards.py)

### Step 1: Install dependencies

You can run this script with **poetry** or plain Python:

```
poetry install
# OR
pip install -r requirements.txt
```

(Dependencies include `requests` and `pandas`.)

### Step 2: Update script configuration

Open the script and update these fields:

```
API_URL = 'https://{YOUR_INSTANCE_URL}.lightdash.cloud'  # Your Lightdash instance
API_KEY = ''                                             # Your Personal Access Token
PROJECT_UUID = ''                                        # Project you want to analyze (REQUIRED)
EXPORT_METHOD = 'csv'                                    # 'csv', 'excel', or 'json'
```

### Step 3: Run the script

Using poetry:

```
poetry run python find_dashboards.py
```

Or directly:

```
python find_dashboards.py
```

## Export All Users in Your Organization

This Python script fetches **all users in your Lightdash organization** using the `/api/v1/org/users` endpoint. This is useful for **audits**, **access reviews**, and **governance**. It returns:

- Full name
- Email
- Role
- Group membership
- Optional Excel or CSV export

### Before You Run This Script

You will need:

- A copy of [get_all_organization_users.py](https://github.com/lightdash/lightdash-api-examples/blob/main/python/get_all_organization_users.py)

### Step 1: Install dependencies

```
pip install requests pandas
```

(or add them to your environment of choice)

### Step 2: Update script configuration

Open the script and replace:

```
API_URL = 'https://<yourinstance>.lightdash.cloud/api/v1/org/users'
API_KEY = '<yourkey>'
EXPORT_METHOD = 'excel'  # or 'csv'
```

### Step 3: Run the script

```
python get_all_organization_users.py
```

## Assign or Update Project Access for a List of Users (Python Utility Script)

This Python script assigns Lightdash **project roles** to a list of users from a CSV file, and upgrades roles when needed. This is useful for **large-scale onboarding**, **role synchronization**, or **managing customer/partner access**. This script handles:

- Bulk granting of project access
- Automatic role upgrades (e.g., viewer → editor)
- Skipping users who already have equal or higher access
- Checking whether users exist in the organization
- Merging org users, project access, and your CSV into one unified dataset

### Before You Run This Script

You will need:

- Python 3.9+ installed
- A Personal Access Token (PAT)
- Your Lightdash instance URL
- The project UUID you want to modify
- A CSV file of users with desired roles
- A copy of `assign_project_access_to_user_list.py`